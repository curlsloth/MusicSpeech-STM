{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886e5242-824a-4224-a27b-0c22ef686f0b",
   "metadata": {},
   "source": [
    "python3 -m pip install -U git+https://github.com/adefossez/demucs#egg=demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da2fa71-e9ea-4172-b7b4-1a4dcad6ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import demucs.api\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5b2005-6670-40d3-b9d2-0a0895ded44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with default parameters:\n",
    "separator = demucs.api.Separator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f611c2c2-26c0-4435-9a17-488c16a9ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# y, sr = librosa.load('/Users/andrewchang/NYU_research/MusicSpeech-STM/data/musicCorp/fma_large/000/000002.mp3')\n",
    "# y, sr = sf.read('/Users/andrewchang/NYU_research/MusicSpeech-STM/data/musicCorp/fma_large/000/000002.mp3')\n",
    "y, sr = torchaudio.load('/Users/andrewchang/NYU_research/MusicSpeech-STM/data/musicCorp/fma_large/000/000002.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd947fcb-c990-4974-8d76-da0ce7c0b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1321344])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bfb3c7-6b6b-4869-bf8d-ffc5e736066b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd3eee3-90cf-49be-aa0c-843eac2d913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b041b858-0d63-4a39-b39e-1729e066443e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1321967])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# # y_2 = np.stack((y, y))\n",
    "# y_tensor = torch.tensor(y)\n",
    "\n",
    "# if y_tensor.shape[0] > y_tensor.shape[1]:\n",
    "#     y_tensor = y_tensor.T\n",
    "\n",
    "# Duplicate and stack the tensor\n",
    "if y.shape[0]==1:\n",
    "    y_tensor = torch.stack((y_tensor, y_tensor), dim=0)\n",
    "\n",
    "y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb479f0-8a79-4617-947f-414a45234dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin, separated = separator.separate_tensor(wav=y_tensor, sr=sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1786aa-318b-48bb-a732-117b34cd3b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drums': tensor([[0.0001, 0.0001, 0.0002,  ..., 0.0015, 0.0011, 0.0011],\n",
       "         [0.0003, 0.0002, 0.0003,  ..., 0.0019, 0.0010, 0.0026]]),\n",
       " 'bass': tensor([[0.0003, 0.0003, 0.0004,  ..., 0.0175, 0.0172, 0.0170],\n",
       "         [0.0004, 0.0003, 0.0004,  ..., 0.0193, 0.0190, 0.0186]]),\n",
       " 'other': tensor([[-1.5053e-05, -1.0797e-05, -1.2832e-04,  ..., -7.2029e-03,\n",
       "          -1.1929e-02, -1.1883e-02],\n",
       "         [ 1.8446e-05,  7.5075e-05,  3.5876e-05,  ..., -2.4766e-03,\n",
       "          -1.2266e-02, -1.0992e-02]]),\n",
       " 'vocals': tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0958, 0.0789, 0.0414],\n",
       "         [0.0004, 0.0004, 0.0004,  ..., 0.1169, 0.1481, 0.1335]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da59f40e-1689-4bcd-94f8-759c68ef11c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1321344])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated['vocals'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37e3a2f1-b08c-4372-96d0-c59b3d4cf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save('voice_test.wav', src=separated['vocals'], sample_rate=sr, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa419bd6-80dd-4712-8c89-f59c43ea82a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120fc22-c727-4e5a-9a52-41a7e0e7b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
