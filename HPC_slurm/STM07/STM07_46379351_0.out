STM_output/corpSTMnpy/BibleTTS-akuapem-twi_STMall.npy
STM_output/corpSTMnpy/BibleTTS-asante-twi_STMall.npy
STM_output/corpSTMnpy/BibleTTS-ewe_STMall.npy
STM_output/corpSTMnpy/BibleTTS-hausa_STMall.npy
STM_output/corpSTMnpy/BibleTTS-lingala_STMall.npy
STM_output/corpSTMnpy/BibleTTS-yoruba_STMall.npy
STM_output/corpSTMnpy/Buckeye_STMall.npy
STM_output/corpSTMnpy/EUROM_STMall.npy
STM_output/corpSTMnpy/HiltonMoser2022_speech_STMall.npy
STM_output/corpSTMnpy/LibriSpeech_STMall.npy
STM_output/corpSTMnpy/MediaSpeech-AR_STMall.npy
STM_output/corpSTMnpy/MediaSpeech-ES_STMall.npy
STM_output/corpSTMnpy/MediaSpeech-FR_STMall.npy
STM_output/corpSTMnpy/MediaSpeech-TR_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ab_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ar_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ba_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-be_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-bg_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-bn_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-br_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ca_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ckb_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-cnh_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-cs_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-cv_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-cy_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-da_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-de_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-dv_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-el_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-en_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-eo_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-es_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-et_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-eu_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-fa_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-fi_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-fr_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-fy-NL_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ga-IE_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-gl_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-gn_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-hi_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-hu_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-hy-AM_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-id_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ig_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-it_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ja_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ka_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-kab_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-kk_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-kmr_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ky_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-lg_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-lt_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ltg_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-lv_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-mhr_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ml_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-mn_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-mt_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-nan-tw_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-nl_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-oc_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-or_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-pl_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-pt_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ro_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ru_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-rw_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-sr_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-sv-SE_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-sw_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ta_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-th_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-tr_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-tt_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ug_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-uk_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-ur_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-uz_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-vi_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-yo_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-yue_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-zh-CN_STMall.npy
STM_output/corpSTMnpy/MozillaCommonVoice-zh-TW_STMall.npy
STM_output/corpSTMnpy/SpeechClarity_STMall.npy
STM_output/corpSTMnpy/TAT-Vol2_STMall.npy
STM_output/corpSTMnpy/TIMIT_STMall.npy
STM_output/corpSTMnpy/TTS_Javanese_STMall.npy
STM_output/corpSTMnpy/primewords_chinese_STMall.npy
STM_output/corpSTMnpy/room_reader_STMall.npy
STM_output/corpSTMnpy/thchs30_STMall.npy
STM_output/corpSTMnpy/zeroth_korean_STMall.npy
STM_output/corpSTMnpy/Albouy2020Science_STMall.npy
STM_output/corpSTMnpy/CD_STMall.npy
STM_output/corpSTMnpy/GarlandEncyclopedia_STMall.npy
STM_output/corpSTMnpy/HiltonMoser2022_song_STMall.npy
STM_output/corpSTMnpy/IRMAS_STMall.npy
STM_output/corpSTMnpy/MTG-Jamendo_STMall.npy
STM_output/corpSTMnpy/MagnaTagATune_STMall.npy
STM_output/corpSTMnpy/NHS2_STMall.npy
STM_output/corpSTMnpy/fma_large_STMall.npy
STM_output/corpSTMnpy/ismir04_genre_STMall.npy
STM_output/corpSTMnpy/SONYC_STMall.npy
STM_output/corpSTMnpy/SONYC_augmented_STMall.npy
Traceback (most recent call last):
  File "/vast/ac8888/MusicSpeech-STM/STM07_tSNE_PCA.py", line 162, in <module>
    STM_MDS = pipeline_MDS.fit_transform(STM_all)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/pipeline.py", line 543, in fit_transform
    return last_step.fit_transform(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/manifold/_mds.py", line 636, in fit_transform
    self.dissimilarity_matrix_ = euclidean_distances(X)
                                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 347, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 379, in _euclidean_distances
    distances = _euclidean_distances_upcast(X, XX, Y, YY)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/envs/MusicSpeech-STMhpc/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 540, in _euclidean_distances_upcast
    distances = np.empty((n_samples_X, n_samples_Y), dtype=np.float32)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.97 TiB for an array with shape (1045169, 1045169) and data type float32
