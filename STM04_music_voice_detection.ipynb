{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e671721f-2139-46b3-bdd3-2b281b407d32",
   "metadata": {},
   "source": [
    "python3 -m pip install -U git+https://github.com/adefossez/demucs#egg=demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bbb83-a99b-4f3d-b0e6-7fbd58bffe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import demucs.api\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "# import kagglehub\n",
    "# path = kagglehub.model_download(\"google/yamnet/tensorFlow2/yamnet\")\n",
    "path = 'yamnet/tensorFlow2/yamnet/1'\n",
    "model = tf.saved_model.load(path, tags=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262264c1-07b2-4a0f-b14b-74a78f91e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('STM_output/STM_metaData/metaData_fma_large.csv', index_col=0)\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327232a-5494-42f7-a044-e2e0adc22552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from here: https://www.tensorflow.org/hub/tutorials/yamnet\n",
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "    class_names = []\n",
    "    with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            class_names.append(row['display_name'])\n",
    "    \n",
    "    return class_names\n",
    "\n",
    "class_map_path = model.class_map_path().numpy()\n",
    "class_names = class_names_from_csv(class_map_path)\n",
    "\n",
    "# verify and convert a loaded audio is on the proper sample_rate (16K), otherwise it would affect the model's results.\n",
    "def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n",
    "    \"\"\"Resample waveform if required.\"\"\"\n",
    "    if original_sample_rate != desired_sample_rate:\n",
    "        desired_length = int(round(float(len(waveform)) / original_sample_rate * desired_sample_rate))\n",
    "        waveform = scipy.signal.resample(waveform, desired_length)\n",
    "    return desired_sample_rate, waveform\n",
    "\n",
    "def estimate_voice(df_meta, n_row)\n",
    "    # st = time.time()\n",
    "    \n",
    "    filename = df_meta['filepath'].iloc[n_row]\n",
    "    frame_offset = df_meta['startPoint'].iloc[n_row]-1\n",
    "    num_frame = df_meta['endPoint'].iloc[n_row]-frame_offset+1\n",
    "    y_tensor, sr = torchaudio.load(filename, frame_offset=frame_offset, num_frames=num_frame)\n",
    "    \n",
    "    # if the audio is mono, duplicate the channel\n",
    "    if y_tensor.shape[0]==1:\n",
    "        y_tensor = torch.stack((y_tensor, y_tensor), dim=0)\n",
    "    \n",
    "    # demucs.api.Separator() by default will make sure the sampling rate is at 44.1 kHz\n",
    "    separator = demucs.api.Separator()\n",
    "    origin, separated = separator.separate_tensor(wav=y_tensor, sr=sr)\n",
    "    \n",
    "    # convert sampling rate and feed into YAMNet\n",
    "    _, waveform = ensure_sample_rate(44100, np.array(separated['vocals'].mean(axis=0))) # convert to sr=16000\n",
    "    scores, _, _ = model(np.array(separated['vocals'].mean(axis=0))) # use YAMNET to score the audio waveform\n",
    "    scores_np = scores.numpy()\n",
    "    infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
    "    voice = infered_class in class_names[0:35] # whether the max likelihood category belongs to any labels of human voice\n",
    "\n",
    "    # # get the execution time\n",
    "    # et = time.time()\n",
    "    # print('Execution time:', et - st, 'seconds')\n",
    "\n",
    "    return voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106d9c67-6c18-4efc-8933-c509644f9f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 8, 2, 20, 18, 16, 10, 14, 12]\n"
     ]
    }
   ],
   "source": [
    "# not done yet...\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "def process_data(data):\n",
    "    # Process data here\n",
    "    return data * 2\n",
    "\n",
    "def parallel_processing(data_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to the executor\n",
    "        futures = [executor.submit(process_data, data) for data in data_list]\n",
    "        \n",
    "        # Gather results\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    processed_data = parallel_processing(data_list)\n",
    "    print(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d658c-2617-4f72-adcb-1d7e18c99b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
